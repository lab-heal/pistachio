{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from util import engineer_features, prep_X_y\n",
    "\n",
    "DATA_DIR = Path(\"./pistachio_1_data\")\n",
    "dyads_df = pd.read_csv(DATA_DIR / \"all_dyads.csv\")\n",
    "\n",
    "sorted_dyads_df = dyads_df.sort_values(\n",
    "    by=\"ActivityDateTime\", key=lambda x: pd.to_datetime(x)\n",
    ")\n",
    "cleaned_dyads_dfs = engineer_features(sorted_dyads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d721c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Any, Literal\n",
    "\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    make_scorer,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    FixedThresholdClassifier,\n",
    "    KFold,\n",
    "    PredefinedSplit,\n",
    "    TunedThresholdClassifierCV,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from hr_model import HrModel\n",
    "from util import FeatureSetDataFrames\n",
    "\n",
    "\n",
    "def specificity_score(y_true, y_pred) -> float:\n",
    "    tn = ((y_true == 0) & (y_pred == 0)).sum()\n",
    "    fp = ((y_true == 0) & (y_pred == 1)).sum()\n",
    "    if (tn + fp) == 0:\n",
    "        return float(\"nan\")\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "\n",
    "def find_threshold_ref_specificity(model, X, y, *, verbose=False) -> float:\n",
    "    hr_model = HrModel()\n",
    "\n",
    "    ref_y_pred = hr_model.predict(X)\n",
    "    ref_specificity = specificity_score(y, ref_y_pred)\n",
    "    ref_recall = recall_score(y, ref_y_pred, zero_division=np.nan)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X)\n",
    "    thresholds = np.logspace(-5, 0, 100)\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = (y_pred_proba[:, 1] >= th).astype(int)\n",
    "        specificity = specificity_score(y, y_pred)\n",
    "        recall = recall_score(y, y_pred, zero_division=np.nan)\n",
    "        if specificity >= ref_specificity:\n",
    "            if verbose:\n",
    "                print(f\"Selected threshold: {th}\")\n",
    "                print(f\"Selected specificity: {specificity}, recall: {recall}\")\n",
    "                print(f\"Reference specificity: {ref_specificity}, recall: {ref_recall}\")\n",
    "            return th\n",
    "\n",
    "    raise ValueError(\"No suitable threshold found!\")\n",
    "\n",
    "\n",
    "def find_threshold_ref_specificity_cv(model, df_train, df_val, cv, verbose=False):\n",
    "    X, y = prep_X_y(pd.concat([df_train, df_val]), \"tantrum_within_60m\")\n",
    "    thresholds = []\n",
    "    for train_idx, val_idx in cv.split(df_train):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        th: int | float = find_threshold_ref_specificity(\n",
    "            model, X_val, y_val, verbose=verbose\n",
    "        )\n",
    "        thresholds.append(th)\n",
    "\n",
    "    best_threshold = float(np.mean(thresholds))\n",
    "    if verbose:\n",
    "        print(f\"Cross-validated best threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    model.fit(X, y)\n",
    "    return FixedThresholdClassifier(model, threshold=best_threshold)\n",
    "\n",
    "\n",
    "def youdens_j_score(y_true, y_pred) -> float:\n",
    "    sensitivity = recall_score(y_true, y_pred, zero_division=np.nan)\n",
    "    specificity = specificity_score(y_true, y_pred)\n",
    "    return sensitivity + specificity - 1\n",
    "\n",
    "\n",
    "TuningMethod = (\n",
    "    Literal[\"balanced_accuracy\"]\n",
    "    | Literal[\"youden_index\"]\n",
    "    | Literal[\"cost_sensitive\"]\n",
    "    | Literal[\"ref_specificity\"]\n",
    ")\n",
    "\n",
    "\n",
    "def create_dyad_cv(df_train: pd.DataFrame, n_splits: int = 5) -> PredefinedSplit:\n",
    "    # Create 5-fold CV based on \"dyad\"\n",
    "    dyad_labels = df_train[\"dyad\"]\n",
    "    skf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    folds = np.zeros(len(df_train), dtype=int)\n",
    "    for fold_idx, (_, val_idx) in enumerate(\n",
    "        skf.split(np.zeros(len(dyad_labels)), dyad_labels)\n",
    "    ):\n",
    "        folds[val_idx] = fold_idx\n",
    "    return PredefinedSplit(folds)\n",
    "\n",
    "\n",
    "def cost_sensitive_score(y, y_pred):\n",
    "    cm = confusion_matrix(y, y_pred, labels=[0, 1])\n",
    "\n",
    "    gain_matrix = np.array(\n",
    "        [\n",
    "            [0, -1],  # gain for false positives\n",
    "            [-200, 0],  # gain for false negatives\n",
    "        ]\n",
    "    )\n",
    "    return np.sum(cm * gain_matrix)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    df_train,\n",
    "    df_val,\n",
    "    hyperparams: dict[str, Any],\n",
    "    tuning_method: TuningMethod,\n",
    "):\n",
    "    model = XGBClassifier(**hyperparams)\n",
    "    X_train, y_train = prep_X_y(pd.concat([df_train, df_val]), \"tantrum_within_60m\")\n",
    "    cv = (\n",
    "        create_dyad_cv(df_train)\n",
    "        if len(df_val) == 0\n",
    "        else PredefinedSplit(test_fold=[-1] * len(df_train) + [0] * len(df_val))\n",
    "    )\n",
    "\n",
    "    thresholds = np.logspace(-5, 0, 100)\n",
    "    if tuning_method == \"balanced_accuracy\":\n",
    "        tuned_model = TunedThresholdClassifierCV(\n",
    "            model,\n",
    "            scoring=\"balanced_accuracy\",\n",
    "            thresholds=thresholds,\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        tuned_model.fit(X_train, y_train)\n",
    "        return tuned_model\n",
    "    elif tuning_method == \"youden_index\":\n",
    "        tuned_model = TunedThresholdClassifierCV(\n",
    "            model,\n",
    "            scoring=make_scorer(youdens_j_score),\n",
    "            thresholds=thresholds,\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        tuned_model.fit(X_train, y_train)\n",
    "        return tuned_model\n",
    "    elif tuning_method == \"cost_sensitive\":\n",
    "        tuned_model = TunedThresholdClassifierCV(\n",
    "            model,\n",
    "            scoring=make_scorer(cost_sensitive_score),\n",
    "            thresholds=thresholds,\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        tuned_model.fit(X_train, y_train)\n",
    "        return tuned_model\n",
    "    elif tuning_method == \"ref_specificity\":\n",
    "        return find_threshold_ref_specificity_cv(\n",
    "            model, df_train, df_val, cv, verbose=False\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tuning method: {tuning_method}\")\n",
    "\n",
    "\n",
    "def bootstrap(df: pd.DataFrame, n_samples: int) -> pd.DataFrame:\n",
    "    boot_df = pd.DataFrame()\n",
    "    for _ in range(n_samples):\n",
    "        boot_df = pd.concat(\n",
    "            [\n",
    "                boot_df,\n",
    "                df.sample(frac=1, replace=True, random_state=None),\n",
    "            ]\n",
    "        )\n",
    "    return boot_df\n",
    "\n",
    "\n",
    "def train_and_get_dyad_models(\n",
    "    df_population: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    mode: str,\n",
    "    week: int,\n",
    "    dyad_models: dict[str, TunedThresholdClassifierCV],\n",
    "    tuning_method: TuningMethod,\n",
    "):\n",
    "    min_week = df_test[\"therapy_week\"].min()\n",
    "    if week == min_week:\n",
    "        return dyad_models\n",
    "\n",
    "    new_dyad_models = {}\n",
    "    bootstrap_level = df_test[\"dyad\"].nunique()\n",
    "    match mode:\n",
    "        case \"no_retrain\":\n",
    "            return dyad_models\n",
    "        case \"retrain_dyad\":\n",
    "            for dyad, dyad_df in tqdm(df_test.groupby(\"dyad\"), leave=False):\n",
    "                add_df = dyad_df[dyad_df[\"therapy_week\"] < week]\n",
    "                add_df = bootstrap(add_df, bootstrap_level)\n",
    "\n",
    "                df_train = pd.concat(\n",
    "                    [df_population, add_df[add_df[\"therapy_week\"] < week - 1]]\n",
    "                )\n",
    "                df_val = add_df[add_df[\"therapy_week\"] == week - 1]\n",
    "                new_dyad_models[dyad] = train_model(\n",
    "                    df_train,\n",
    "                    df_val,\n",
    "                    dyad_models[dyad].estimator.get_params(),\n",
    "                    tuning_method,\n",
    "                )\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    return new_dyad_models\n",
    "\n",
    "\n",
    "def retrain_and_predict(\n",
    "    base_model,\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    mode: str,\n",
    "    tuning_method: TuningMethod,\n",
    "):\n",
    "    dyad_models = {d: base_model for d in df_test[\"dyad\"].unique()}\n",
    "    weekly_results = []\n",
    "    weekly_models = []\n",
    "    weeks = df_test[\"therapy_week\"].unique()\n",
    "    weeks_iter = sorted(weeks[weeks >= 0])\n",
    "    for week in tqdm(weeks_iter):\n",
    "        dyad_models = train_and_get_dyad_models(\n",
    "            df_train,\n",
    "            df_test,\n",
    "            mode,\n",
    "            week,\n",
    "            dyad_models=dyad_models,\n",
    "            tuning_method=tuning_method,\n",
    "        )\n",
    "        weekly_models.append((week, dyad_models))\n",
    "        week_df = df_test[df_test[\"therapy_week\"] == week]\n",
    "\n",
    "        week_pred_proba = np.empty((0, 2))\n",
    "        week_preds = np.array([])\n",
    "        week_trues = np.array([])\n",
    "        week_thresholds = np.array([])\n",
    "\n",
    "        for dyad, dyad_week_df in week_df.groupby(\"dyad\"):\n",
    "            X, y = prep_X_y(dyad_week_df, \"tantrum_within_60m\")\n",
    "            model = dyad_models[dyad]\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X)\n",
    "            y_pred = model.predict(X)\n",
    "\n",
    "            week_pred_proba = np.concatenate([week_pred_proba, y_pred_proba])\n",
    "            week_preds = np.concatenate([week_preds, y_pred])\n",
    "            week_trues = np.concatenate([week_trues, y.values])\n",
    "            threshold = (\n",
    "                model.best_threshold_\n",
    "                if isinstance(model, TunedThresholdClassifierCV)\n",
    "                else 0.5\n",
    "            )\n",
    "            week_thresholds = np.append(week_thresholds, threshold)\n",
    "\n",
    "        print(\n",
    "            f\"Week {week} sensitivity: {recall_score(week_trues, week_preds)}, specificity: {specificity_score(week_trues, week_preds)}\"\n",
    "        )\n",
    "        weekly_results.append(\n",
    "            (week, week_pred_proba, week_preds, week_trues, week_thresholds)\n",
    "        )\n",
    "\n",
    "    return weekly_results, weekly_models\n",
    "\n",
    "\n",
    "supersets_to_test = [\n",
    "    [\"watch\"],\n",
    "    [\"watch\", \"demographic\"],\n",
    "    [\"watch\", \"medical\"],\n",
    "    [\"watch\", \"demographic\", \"medical\"],\n",
    "]\n",
    "feature_supersets = {\n",
    "    \"watch\": [\n",
    "        \"hr\",\n",
    "        \"activity\",\n",
    "        \"sleep\",\n",
    "        \"stress\",\n",
    "        \"overnight_hrv\",\n",
    "    ],\n",
    "    \"demographic\": [\n",
    "        \"child_demo\",\n",
    "        \"parent_demo\",\n",
    "    ],\n",
    "    \"medical\": [\n",
    "        \"medical\",\n",
    "        \"therapy\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "automl_settings = {\n",
    "    # \"max_iter\": 25,\n",
    "    \"time_budget\": 15,\n",
    "    \"train_time_limit\": 2,  # seconds\n",
    "    \"pred_time_limit\": 1,  # seconds\n",
    "    \"task\": \"classification\",\n",
    "    # \"metric\": \"log_loss\",\n",
    "    \"estimator_list\": [\"xgboost\"],\n",
    "    \"early_stop\": True,\n",
    "}\n",
    "\n",
    "\n",
    "def eval_model_on_feature_sets(\n",
    "    supersets_to_test: list[list[str]],\n",
    "    dfs: FeatureSetDataFrames,\n",
    "    weeks: tuple[int, int],\n",
    "    mode: str,\n",
    "    tuning_method: TuningMethod,\n",
    "    verbose: bool = False,\n",
    ") -> dict[str, Any]:\n",
    "    feature_set_results = {}\n",
    "    for supersets in supersets_to_test:\n",
    "        features = [fs for superset in supersets for fs in feature_supersets[superset]]\n",
    "        combined_df = pd.concat(\n",
    "            [\n",
    "                cleaned_dyads_dfs[\"index\"],\n",
    "                cleaned_dyads_dfs[\"response\"],\n",
    "            ]\n",
    "            + [cleaned_dyads_dfs[fs] for fs in features],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        name = \"_\".join(supersets)\n",
    "        print(f\"Feature sets: {name}\")\n",
    "\n",
    "        combined_df = combined_df[\n",
    "            (combined_df[\"therapy_week\"].between(weeks[0], weeks[1]))\n",
    "        ]\n",
    "        df_train = combined_df[combined_df[\"Arm_Sham\"]]\n",
    "        df_test = combined_df[~combined_df[\"Arm_Sham\"]]\n",
    "\n",
    "        # Create 5-fold CV based on \"dyad\"\n",
    "        dyad_labels = df_train[\"dyad\"]\n",
    "        skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        folds = np.zeros(len(df_train), dtype=int)\n",
    "        for fold_idx, (_, val_idx) in enumerate(\n",
    "            skf.split(np.zeros(len(dyad_labels)), dyad_labels)\n",
    "        ):\n",
    "            folds[val_idx] = fold_idx\n",
    "        cv = PredefinedSplit(folds)\n",
    "        X_train, y_train = prep_X_y(df_train, \"tantrum_within_60m\")\n",
    "\n",
    "        automl = AutoML()\n",
    "        automl.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            **automl_settings,\n",
    "            verbose=verbose,\n",
    "            eval_method=\"cv\",\n",
    "            split_type=\"group\",\n",
    "            groups=df_train[\"dyad\"],\n",
    "        )\n",
    "        tuned_model = train_model(\n",
    "            df_train,\n",
    "            pd.DataFrame(),\n",
    "            automl.best_config,\n",
    "            tuning_method=tuning_method,\n",
    "        )\n",
    "        results, models = retrain_and_predict(\n",
    "            tuned_model, df_train, df_test, mode=mode, tuning_method=tuning_method\n",
    "        )\n",
    "\n",
    "        data_dir = Path(\"./intermediate_data\")\n",
    "        data_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with open(data_dir / f\"{tuning_method}_{mode}_{name}_results.pkl\", \"wb\") as f:\n",
    "            pickle.dump(results, f)\n",
    "\n",
    "        feature_set_results[name] = results\n",
    "    return feature_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "weeks = (0, 15)\n",
    "tuning_method: TuningMethod = \"youden_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat(list(cleaned_dyads_dfs.values()), axis=1)\n",
    "full_df = full_df[full_df[\"therapy_week\"].between(weeks[0], weeks[1])]\n",
    "full_df_train = full_df[full_df[\"Arm_Sham\"]]\n",
    "full_df_test = full_df[~full_df[\"Arm_Sham\"]]\n",
    "\n",
    "X_train, y_train = prep_X_y(full_df_train, \"tantrum_within_60m\")\n",
    "\n",
    "hr_model_results, _ = retrain_and_predict(\n",
    "    HrModel(),\n",
    "    full_df_train,\n",
    "    full_df_test,\n",
    "    mode=\"no_retrain\",\n",
    "    tuning_method=tuning_method,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ff105",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retrain_results = eval_model_on_feature_sets(\n",
    "    supersets_to_test=supersets_to_test,\n",
    "    dfs=cleaned_dyads_dfs,\n",
    "    weeks=weeks,\n",
    "    mode=\"no_retrain\",\n",
    "    tuning_method=tuning_method,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "test_case = [\n",
    "    [\"watch\"],\n",
    "    [\"watch\", \"demographic\"],\n",
    "    [\"watch\", \"medical\"],\n",
    "    [\"watch\", \"demographic\", \"medical\"],\n",
    "]\n",
    "\n",
    "retrain_dyad_results = eval_model_on_feature_sets(\n",
    "    supersets_to_test=test_case,\n",
    "    dfs=cleaned_dyads_dfs,\n",
    "    weeks=weeks,\n",
    "    mode=\"retrain_dyad\",\n",
    "    tuning_method=tuning_method,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424918b",
   "metadata": {},
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d192a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tuning_method: TuningMethod = \"youden_index\"\n",
    "feature_sets = [\n",
    "    \"watch\",\n",
    "    \"watch_demographic\",\n",
    "    \"watch_medical\",\n",
    "    \"watch_demographic_medical\",\n",
    "]\n",
    "data_dir = Path(\"./intermediate_data\")\n",
    "no_retrain_results = {\n",
    "    k: pickle.load(open(data_dir / f\"{tuning_method}_no_retrain_{k}_results.pkl\", \"rb\"))\n",
    "    for k in feature_sets\n",
    "}\n",
    "retrain_dyad_results = {\n",
    "    k: pickle.load(\n",
    "        open(data_dir / f\"{tuning_method}_retrain_dyad_{k}_results.pkl\", \"rb\")\n",
    "    )\n",
    "    for k in feature_sets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_weekly_cum_metric(metric_name, metric_fn):\n",
    "    def weekly_cum_metric(results, metric_fn):\n",
    "        metrics = []\n",
    "        all_y_pred_proba = np.empty((0, 2))\n",
    "        all_y_pred = np.array([])\n",
    "        all_y_true = np.array([])\n",
    "        for week, y_pred_proba, y_pred, y_true, _ in results:\n",
    "            all_y_pred_proba = np.concatenate([all_y_pred_proba, y_pred_proba])\n",
    "            all_y_pred = np.concatenate([all_y_pred, y_pred])\n",
    "            all_y_true = np.concatenate([all_y_true, y_true])\n",
    "\n",
    "            if metric_fn is roc_auc_score:\n",
    "                metric = metric_fn(all_y_true, all_y_pred_proba[:, 1])\n",
    "            else:\n",
    "                metric = metric_fn(all_y_true, all_y_pred)\n",
    "            metrics.append((week, metric))\n",
    "        return metrics\n",
    "\n",
    "    hr_cum_auc = weekly_cum_metric(hr_model_results, metric_fn)\n",
    "    no_retrain_watch_cum_auc = weekly_cum_metric(no_retrain_results[\"watch\"], metric_fn)\n",
    "    no_retrain_demographic_cum_auc = weekly_cum_metric(\n",
    "        no_retrain_results[\"watch_demographic\"], metric_fn\n",
    "    )\n",
    "    no_retrain_medical_metric = weekly_cum_metric(\n",
    "        no_retrain_results[\"watch_medical\"], metric_fn\n",
    "    )\n",
    "    no_retrain_all_features_metric = weekly_cum_metric(\n",
    "        no_retrain_results[\"watch_demographic_medical\"], metric_fn\n",
    "    )\n",
    "    retrain_watch_cum_auc = weekly_cum_metric(retrain_dyad_results[\"watch\"], metric_fn)\n",
    "    retrain_demographic_cum_auc = weekly_cum_metric(\n",
    "        retrain_dyad_results[\"watch_demographic\"], metric_fn\n",
    "    )\n",
    "    retrain_medical_metric = weekly_cum_metric(\n",
    "        retrain_dyad_results[\"watch_medical\"], metric_fn\n",
    "    )\n",
    "    retrain_medical_cum_auc = weekly_cum_metric(\n",
    "        retrain_dyad_results[\"watch_demographic_medical\"], metric_fn\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(*zip(*hr_cum_auc), label=\"HR range (105-129)\", color=\"tab:grey\")\n",
    "\n",
    "    plt.plot(*zip(*no_retrain_watch_cum_auc), label=\"Watch - No Retrain\", linestyle=\":\")\n",
    "    plt.plot(\n",
    "        *zip(*no_retrain_demographic_cum_auc),\n",
    "        label=\"Watch, Demographic - No Retrain\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        *zip(*no_retrain_medical_metric),\n",
    "        label=\"Watch, Medical - No Retrain\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        *zip(*no_retrain_all_features_metric),\n",
    "        label=\"Watch, Demographic, Medical - No Retrain\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        *zip(*retrain_watch_cum_auc), label=\"Watch - Retrain Weekly\", color=\"tab:blue\"\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        *zip(*retrain_demographic_cum_auc),\n",
    "        label=\"Watch, Demographic - Retrain Weekly\",\n",
    "        color=\"tab:orange\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        *zip(*retrain_medical_metric),\n",
    "        label=\"Watch, Medical - Retrain Weekly\",\n",
    "        color=\"tab:green\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        *zip(*retrain_medical_cum_auc),\n",
    "        label=\"Watch, Demographic, Medical - Retrain Weekly\",\n",
    "        color=\"tab:red\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Therapy Week\")\n",
    "    plt.ylabel(f\"Cumulative {metric_name}\")\n",
    "    plt.title(f\"Cumulative {metric_name} by Model\")\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_final_metrics():\n",
    "    def get_final_metric(results, metric_fn):\n",
    "        all_y_pred_proba = np.empty((0, 2))\n",
    "        all_y_pred = np.array([])\n",
    "        all_y_true = np.array([])\n",
    "        for _, y_pred_proba, y_pred, y_true, _ in results:\n",
    "            all_y_pred_proba = np.concatenate([all_y_pred_proba, y_pred_proba])\n",
    "            all_y_pred = np.concatenate([all_y_pred, y_pred])\n",
    "            all_y_true = np.concatenate([all_y_true, y_true])\n",
    "        if metric_fn is roc_auc_score:\n",
    "            return metric_fn(all_y_true, all_y_pred_proba[:, 1])\n",
    "        else:\n",
    "            return metric_fn(all_y_true, all_y_pred)\n",
    "\n",
    "    models = [\n",
    "        (\"HR range (105-129)\", hr_model_results),\n",
    "        (\"Watch - No Retrain\", no_retrain_results[\"watch\"]),\n",
    "        (\n",
    "            \"Watch, Demographic - No Retrain\",\n",
    "            no_retrain_results[\"watch_demographic\"],\n",
    "        ),\n",
    "        (\"Watch, Medical - No Retrain\", no_retrain_results[\"watch_medical\"]),\n",
    "        (\n",
    "            \"Watch, Demographic, Medical - No Retrain\",\n",
    "            no_retrain_results[\"watch_demographic_medical\"],\n",
    "        ),\n",
    "        (\"Watch - Retrain Weekly\", retrain_dyad_results[\"watch\"]),\n",
    "        (\n",
    "            \"Watch, Demographic - Retrain Weekly\",\n",
    "            retrain_dyad_results[\"watch_demographic\"],\n",
    "        ),\n",
    "        (\"Watch, Medical - Retrain Weekly\", retrain_dyad_results[\"watch_medical\"]),\n",
    "        (\n",
    "            \"Watch, Demographic, Medical - Retrain Weekly\",\n",
    "            retrain_dyad_results[\"watch_demographic_medical\"],\n",
    "        ),\n",
    "    ]\n",
    "    # Collect metrics into a DataFrame and print as markdown\n",
    "\n",
    "    rows = []\n",
    "    for name, results in models:\n",
    "        auroc = get_final_metric(results, roc_auc_score)\n",
    "        sensitivity = get_final_metric(results, recall_score)\n",
    "        specificity = get_final_metric(results, specificity_score)\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Model\": name,\n",
    "                \"AUROC\": round(auroc, 3),\n",
    "                \"Sensitivity\": round(sensitivity, 3),\n",
    "                \"Specificity\": round(specificity, 3),\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows).set_index(\"Model\")\n",
    "\n",
    "\n",
    "print(get_final_metrics())\n",
    "plot_weekly_cum_metric(\"AUROC\", roc_auc_score)\n",
    "plot_weekly_cum_metric(\"Sensitivity\", recall_score)\n",
    "plot_weekly_cum_metric(\"Specificity\", specificity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21142fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41de942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much can we improve the HR range model\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hr_model import HrModel\n",
    "\n",
    "full_df = pd.concat(list(cleaned_dyads_dfs.values()), axis=1)\n",
    "full_df = full_df[full_df[\"therapy_week\"].between(weeks[0], weeks[1])]\n",
    "full_df_train = full_df[full_df[\"Arm_Sham\"]]\n",
    "full_df_test = full_df[~full_df[\"Arm_Sham\"]]\n",
    "\n",
    "X_train, y_train = prep_X_y(full_df_train, \"tantrum_within_60m\")\n",
    "\n",
    "best_auc = -1\n",
    "best_hr_low = None\n",
    "best_hr_high = None\n",
    "best_sens = None\n",
    "best_spec = None\n",
    "\n",
    "hr_lows = range(50, 150, 2)\n",
    "hr_highs = range(100, 200, 2)\n",
    "\n",
    "for combo in tqdm(list(itertools.product(hr_lows, hr_highs))):\n",
    "    hr_low, hr_high = combo\n",
    "\n",
    "    if hr_high <= hr_low:\n",
    "        continue\n",
    "    # Predict using HR range\n",
    "    y_pred = (\n",
    "        (full_df_train[\"hr_moving_avg_10m\"] >= hr_low)\n",
    "        & (full_df_train[\"hr_moving_avg_10m\"] <= hr_high)\n",
    "    ).astype(int)\n",
    "    y_true = y_train\n",
    "\n",
    "    # Only evaluate where hr_moving_avg_10m is not NaN\n",
    "    mask = full_df_train[\"hr_moving_avg_10m\"].notna()\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    auc = roc_auc_score(y_true[mask], y_pred[mask])\n",
    "    sens = recall_score(y_true[mask], y_pred[mask])\n",
    "    spec = specificity_score(y_true[mask], y_pred[mask])\n",
    "\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_hr_low = hr_low\n",
    "        best_hr_high = hr_high\n",
    "        best_sens = sens\n",
    "        best_spec = spec\n",
    "\n",
    "print(f\"Best HR range: {best_hr_low}-{best_hr_high}\")\n",
    "print(f\"ROC-AUC: {best_auc:.3f}\")\n",
    "print(f\"Sensitivity: {best_sens:.3f}\")\n",
    "print(f\"Specificity: {best_spec:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pistachio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
