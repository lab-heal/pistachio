{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698fd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b778d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./pistachio_1_data\")\n",
    "DEVICE_DATA_DIR = DATA_DIR / \"SMRawDec27\"\n",
    "\n",
    "cohort_df = pd.read_csv(DATA_DIR / \"cohort_analysis.csv\")\n",
    "pdi_sheets = pd.read_excel(DATA_DIR / \"Artificial_PDI_12-27.xlsx\", sheet_name=None)\n",
    "assert len(pdi_sheets) == 1\n",
    "pdi_start_dates_df = pdi_sheets[\"PDI start dates\"]\n",
    "\n",
    "dyads_df = pd.merge(cohort_df, pdi_start_dates_df, on=\"ID\", how=\"left\")\n",
    "dyads_df = dyads_df.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrv import daily_hrv_sdann_sleep\n",
    "from util import FORMAT_DAY, FORMAT_MIN, FORMAT_SEC\n",
    "\n",
    "NIGHTTIME_CUTOFF = time(18, 0)\n",
    "TANTRUM_INTERVAL_MINUTES = [15, 30, 45, 60]\n",
    "\n",
    "\n",
    "def make_dyad_df(dyad: int) -> pd.DataFrame:\n",
    "    dyad_code = f\"{dyad:03d}\"\n",
    "\n",
    "    ## Activity\n",
    "    # Data every 15 minutes\n",
    "    epoch_df = get_child_garmin_df(dyad_code, \"Epoch\")\n",
    "    epoch_log_df = get_child_garmin_df(dyad_code, \"EpochLog\")\n",
    "\n",
    "    # Add total activity seconds by intensity to each epoch\n",
    "    epoch_df_ext = epoch_df.copy().set_index(\"ActivityDateTime\")\n",
    "    for intensity in [\"SEDENTARY\", \"ACTIVE\", \"HIGHLY_ACTIVE\"]:\n",
    "        epoch_df_ext = add_activity_intensity_to_epoch_df(\n",
    "            epoch_df_ext, epoch_log_df, intensity\n",
    "        )\n",
    "\n",
    "    ## Sleep\n",
    "    # Daily summaries of sleep (e.g., total REM for a night)\n",
    "    sleep_df = get_child_garmin_df(dyad_code, \"Sleep\")\n",
    "    sleep_df[\"CalendarDate\"] = pd.to_datetime(\n",
    "        sleep_df[\"CalendarDate\"], format=FORMAT_DAY\n",
    "    )\n",
    "    # Each detected sleep stage with its own row w/start time, duration\n",
    "    sleep_details_df = get_child_garmin_df(dyad_code, \"SleepDetails\")\n",
    "    # Summarize sleep details\n",
    "    sleep_summary_df = summarize_sleep_details(\n",
    "        sleep_details_df, nighttime_cutoff=NIGHTTIME_CUTOFF\n",
    "    )\n",
    "\n",
    "    ## Heart rate\n",
    "    hr_df = get_child_garmin_df(dyad_code, \"HeartRate\")\n",
    "    hr_df[\"ActivityTime\"] = pd.to_datetime(hr_df[\"ActivityTime\"], format=FORMAT_SEC)\n",
    "\n",
    "    ## Stress\n",
    "    # Daily stress summary\n",
    "    stress_df = get_child_garmin_df(dyad_code, \"Stress\")\n",
    "    stress_df[\"ActivityDateTime\"] = pd.to_datetime(\n",
    "        stress_df[\"ActivityDateTime\"], format=FORMAT_MIN\n",
    "    )\n",
    "    stress_df = stress_df.set_index(stress_df[\"ActivityDateTime\"].dt.date).drop(\n",
    "        [\"ActivityDateTime\"], axis=1\n",
    "    )\n",
    "\n",
    "    # High resolution stress (every 3 minutes)\n",
    "    stress_details_df = get_child_garmin_df(dyad_code, \"StressDetails\")\n",
    "    # Rollup stress_details_df to 15-minute bins, averaging StressLevelValue (ignoring -1)\n",
    "    stress_details_df[\"ActivityDate\"] = pd.to_datetime(\n",
    "        stress_details_df[\"ActivityDate\"]\n",
    "    )\n",
    "    stress_details_df = stress_details_df[stress_details_df[\"StressLevelValue\"] != -1]\n",
    "    stress_details_summary_df = (\n",
    "        stress_details_df.set_index(\"ActivityDate\")\n",
    "        .resample(\"15min\")[\"StressLevelValue\"]\n",
    "        .mean()\n",
    "        .to_frame()\n",
    "        .rename(columns={\"StressLevelValue\": \"StressLevelValueAverage\"})\n",
    "    )\n",
    "\n",
    "    ## EMA logs\n",
    "    ilumivu_dfs = get_ilumivu_dfs(dyad_code)\n",
    "    tantrums_df = tantrum_onsets_from_ilumivu_dfs(*ilumivu_dfs)\n",
    "\n",
    "    ## Now combine all the dataframes\n",
    "    combined_df = epoch_df_ext.copy()\n",
    "    for interval in [\"10m\", \"30m\", \"60m\"]:\n",
    "        recent_hrs_by_time = pd.Series(\n",
    "            [\n",
    "                most_recent_hrs(\n",
    "                    hr_df, pd.to_datetime(time), lookback=pd.Timedelta(interval)\n",
    "                )\n",
    "                for time, _ in epoch_df_ext.iterrows()\n",
    "            ],\n",
    "            index=epoch_df_ext.index,\n",
    "        )\n",
    "        combined_df[f\"hr_moving_avg_{interval}\"] = recent_hrs_by_time.map(np.mean)\n",
    "        combined_df[f\"hr_moving_std_{interval}\"] = recent_hrs_by_time.map(np.std)\n",
    "        combined_df[f\"hr_moving_max_{interval}\"] = recent_hrs_by_time.map(np.max)\n",
    "        combined_df[f\"hr_moving_min_{interval}\"] = recent_hrs_by_time.map(np.min)\n",
    "\n",
    "    combined_df[\"ActivityDateTimeDt\"] = pd.to_datetime(\n",
    "        combined_df.index, format=FORMAT_MIN\n",
    "    )\n",
    "    combined_df = combined_df.join(\n",
    "        stress_details_summary_df, on=\"ActivityDateTimeDt\", how=\"left\"\n",
    "    )\n",
    "    combined_df = combined_df.drop(columns=[\"ActivityDateTimeDt\"])\n",
    "\n",
    "    hrv_df = daily_hrv_sdann_sleep(hr_df, sleep_df)\n",
    "    combined_df[\"ActivityDate\"] = pd.to_datetime(\n",
    "        combined_df.index, format=FORMAT_MIN\n",
    "    ).date\n",
    "    combined_df = combined_df.join(\n",
    "        hrv_df,\n",
    "        on=\"ActivityDate\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    combined_df = combined_df.drop(columns=[\"ActivityDate\"])\n",
    "\n",
    "    # Look at stress over the past 1 to 6 days\n",
    "    stress_lookback_days = 5\n",
    "    for day in range(1, stress_lookback_days + 1):\n",
    "        temp_col = f\"StressDate_T-{day}\"\n",
    "        temp_df = stress_df.copy().add_suffix(f\"_T-{day}\")\n",
    "        combined_df[temp_col] = pd.to_datetime(combined_df.index).date - pd.Timedelta(\n",
    "            days=day\n",
    "        )\n",
    "        combined_df = combined_df.join(temp_df, on=temp_col, how=\"left\")\n",
    "        combined_df = combined_df.drop(columns=[temp_col])\n",
    "\n",
    "    # Look at sleep over the past 0 to 5 days (sleep from the previous night is marked by the waking date)\n",
    "    sleep_lookback_days = 5\n",
    "    for day in range(sleep_lookback_days):\n",
    "        temp_col = f\"SleepNightT_{day}\"\n",
    "        temp_df = sleep_summary_df.copy().add_suffix(f\"_T-{day}\")\n",
    "        combined_df[temp_col] = pd.to_datetime(combined_df.index).date - pd.Timedelta(\n",
    "            days=day\n",
    "        )\n",
    "        combined_df = combined_df.join(temp_df, on=temp_col, how=\"left\")\n",
    "        combined_df = combined_df.drop(columns=[temp_col])\n",
    "\n",
    "    activity_times = pd.to_datetime(combined_df.index)\n",
    "    tantrum_starts = tantrums_df.sort_values().to_numpy()\n",
    "    for interval in TANTRUM_INTERVAL_MINUTES:\n",
    "        combined_df[f\"tantrum_within_{interval}m\"] = activity_times.map(\n",
    "            lambda x: has_tantrum_within_period_minutes(tantrum_starts, x, interval)\n",
    "        )\n",
    "\n",
    "    for col in dyads_df.columns:\n",
    "        combined_df[col] = dyads_df.loc[dyad, col]\n",
    "\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    combined_df.rename(columns={\"index\": \"ActivityDateTime\"}, inplace=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def get_child_garmin_df(dyad: str, csv_name: str) -> pd.DataFrame:\n",
    "    # Example name: pistachio003_c_garminActivity_20220325_20220721.csv\n",
    "    glob = f\"*_garmin{csv_name}_*.csv\"  # Need flanking underscores bc some names (e.g., garminActivity) are prefixes\n",
    "    child = f\"{dyad}_C\"\n",
    "    [csv] = list((DEVICE_DATA_DIR / child / \"Garmin\").glob(glob))\n",
    "    return pd.read_csv(csv)\n",
    "\n",
    "\n",
    "def summarize_sleep_details(\n",
    "    sleep_details_df: pd.DataFrame, nighttime_cutoff: time\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Summarize sleep details similar to the garminSleep CSV, but using a different cutoff than midnight\"\"\"\n",
    "\n",
    "    sleep_details_df[\"ActivityDateTime\"] = pd.to_datetime(\n",
    "        sleep_details_df[\"ActivityDateTime\"], format=\"mixed\"\n",
    "    )\n",
    "    sleep_date_col = \"SleepNightT-1\"\n",
    "    sleep_details_df[sleep_date_col] = sleep_details_df[\"ActivityDateTime\"].apply(\n",
    "        lambda dt: dt.date()\n",
    "        if dt.time() < nighttime_cutoff\n",
    "        else dt.date() + pd.Timedelta(days=1)\n",
    "    )\n",
    "    sleep_summary = (\n",
    "        sleep_details_df.groupby([sleep_date_col, \"SleepStage\"])[\"Duration\"]\n",
    "        .sum()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "    return sleep_summary\n",
    "\n",
    "\n",
    "def add_activity_intensity_to_epoch_df(\n",
    "    epoch_df_ext: pd.DataFrame,\n",
    "    epoch_log_df: pd.DataFrame,\n",
    "    intensity: str,\n",
    ") -> pd.DataFrame:\n",
    "    grouped = epoch_log_df.groupby([\"ActivityDateTime\", \"Intensity\"])[\n",
    "        \"ActiveTimeInSeconds\"\n",
    "    ].sum()\n",
    "    intensity_seconds = grouped.loc[(epoch_df_ext.index, intensity)].drop(  # pyright: ignore[reportCallIssue,reportArgumentType]\n",
    "        columns=[\"Intensity\"]\n",
    "    )\n",
    "    intensity_seconds.index = intensity_seconds.index.get_level_values(0)\n",
    "    col_name = f\"activity_seconds_{intensity.lower()}\"  # pyright: ignore[reportCallIssue]\n",
    "    epoch_df_ext[col_name] = intensity_seconds\n",
    "    epoch_df_ext[col_name] = epoch_df_ext[col_name].fillna(0)\n",
    "    return epoch_df_ext\n",
    "\n",
    "\n",
    "def get_ilumivu_df(subject_dir: Path) -> pd.DataFrame | None:\n",
    "    ilumivu_dir = [\n",
    "        d\n",
    "        for d in subject_dir.iterdir()\n",
    "        # It looks like all filenames start with \"Ilumivu\" but some actually start with ZERO WIDTH SPACE?!?\n",
    "        if d.is_dir() and (\"Ilumivu\" in d.name or \"Illumivu\" in d.name)\n",
    "    ]\n",
    "    if not ilumivu_dir:\n",
    "        return None\n",
    "\n",
    "    [ilumivu_dir] = ilumivu_dir\n",
    "    for f in ilumivu_dir.iterdir():\n",
    "        if f.name.endswith(\".csv\"):\n",
    "            return pd.read_csv(f)\n",
    "\n",
    "    # Some folders are empty\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_ilumivu_dfs(dyad: str) -> tuple[pd.DataFrame, pd.DataFrame | None]:\n",
    "    \"\"\"Ilumivu data for the child is only available if the dyad is in the Active (AI) arm.\"\"\"\n",
    "    # This directory doesn't have a standard name, but they all start with Ilumivu\n",
    "    parent = f\"{dyad}_P\"\n",
    "    child = f\"{dyad}_C\"\n",
    "\n",
    "    parent_df = get_ilumivu_df(DEVICE_DATA_DIR / parent)\n",
    "    if parent_df is None:\n",
    "        assert dyad == \"049\"\n",
    "        parent_df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"survey_name\",\n",
    "                \"mobile_code\",\n",
    "                \"instance_id\",\n",
    "                \"instance_date\",\n",
    "                \"item_id\",\n",
    "                \"question_code\",\n",
    "                \"answer_code\",\n",
    "                \"answer_value\",\n",
    "                \"page_visible\",\n",
    "                \"answer_clicked\",\n",
    "                \"seconds_to_respond\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    child_df = get_ilumivu_df(DEVICE_DATA_DIR / child)\n",
    "    active_dyads = [\n",
    "        f\"{d:03d}\" for d in dyads_df[(dyads_df[\"Arm\"] == \"Active\")].index.tolist()\n",
    "    ]\n",
    "    if dyad not in active_dyads:\n",
    "        assert child_df is None, f\"Sham dyad {dyad} should not have child Ilumivu data\"\n",
    "    return parent_df, child_df\n",
    "\n",
    "\n",
    "def datetime_from_survey_answer(time: str) -> datetime:\n",
    "    \"\"\"Survey answer example: '1:45PM/1649443501.804'\"\"\"\n",
    "    timestamp = float(time.split(\"/\")[1])\n",
    "    return datetime.fromtimestamp(timestamp)\n",
    "\n",
    "\n",
    "def tantrum_onsets_from_ilumivu_dfs(\n",
    "    parent_df: pd.DataFrame,\n",
    "    child_df: pd.DataFrame | None,\n",
    "    verbose: bool = False,\n",
    ") -> pd.Series:\n",
    "    tantrums = []\n",
    "    invalid_count = {\n",
    "        \"no_end\": 0,\n",
    "        \"submit_before_end\": 0,\n",
    "        \"negative_duration\": 0,\n",
    "        \"excessive_duration\": 0,\n",
    "        \"overlap\": 0,\n",
    "    }\n",
    "\n",
    "    def get_tantrums(df: pd.DataFrame, start_key: str, end_key: str):\n",
    "        tantrum_start_indices = df[df[\"question_code\"] == start_key].index\n",
    "        for start_index in tantrum_start_indices:\n",
    "            tantrum_start = datetime_from_survey_answer(\n",
    "                str(df.loc[start_index, \"answer_code\"])\n",
    "            )\n",
    "            tantrum_end = None\n",
    "\n",
    "            if (\n",
    "                start_index + 1 in df.index\n",
    "                and df.loc[start_index + 1, \"question_code\"] == end_key\n",
    "            ):\n",
    "                tantrum_end = datetime_from_survey_answer(\n",
    "                    str(df.loc[start_index + 1, \"answer_code\"])\n",
    "                )\n",
    "\n",
    "            tantrum_end_input_date = datetime.fromisoformat(\n",
    "                df.loc[start_index + 1, \"instance_date\"]\n",
    "            )\n",
    "\n",
    "            submit_grace_period = pd.Timedelta(minutes=1)\n",
    "            # Criteria that Kyle and Arjun discussed a while ago\n",
    "            if tantrum_end is None:\n",
    "                invalid_count[\"no_end\"] += 1\n",
    "                continue\n",
    "            # We expect the survey to be submitted after the tantrum ends\n",
    "            if (tantrum_end_input_date + submit_grace_period) < tantrum_end:\n",
    "                invalid_count[\"submit_before_end\"] += 1\n",
    "                continue\n",
    "            duration = tantrum_end - tantrum_start\n",
    "            if duration < pd.Timedelta(0):\n",
    "                invalid_count[\"negative_duration\"] += 1\n",
    "                continue\n",
    "            tantrums.append((tantrum_start, tantrum_end))\n",
    "        return tantrums\n",
    "\n",
    "    tantrums = get_tantrums(\n",
    "        parent_df, \"TIME_OF_ONSET_OF_TANTRUM\", \"END_TIME_OF_TANTRUM\"\n",
    "    )\n",
    "    if child_df is not None:\n",
    "        tantrums += get_tantrums(child_df, \"TANTRUM_START\", \"TANTRUM_END\")\n",
    "\n",
    "    # Combine overlapping tantrums into a single interval\n",
    "    if tantrums:\n",
    "        tantrums.sort(key=lambda x: x[0])\n",
    "        merged_tantrums = []\n",
    "        current_start, current_end = tantrums[0]\n",
    "        for start, end in tantrums[1:]:\n",
    "            if start <= current_end:\n",
    "                # Overlap: extend the current interval\n",
    "                invalid_count[\"overlap\"] += 1\n",
    "                current_end = max(current_end, end)\n",
    "            else:\n",
    "                # No overlap: save current and start new\n",
    "                merged_tantrums.append((current_start, current_end))\n",
    "                current_start, current_end = start, end\n",
    "        merged_tantrums.append((current_start, current_end))\n",
    "        tantrums = merged_tantrums\n",
    "\n",
    "    # Remove tantrums that are excessively long\n",
    "    to_remove = []\n",
    "    for i, (tantrum_start, tantrum_end) in enumerate(tantrums):\n",
    "        duration = tantrum_end - tantrum_start\n",
    "        if duration > pd.Timedelta(seconds=3600 * 2):\n",
    "            invalid_count[\"excessive_duration\"] += 1\n",
    "            to_remove.append(i)\n",
    "    tantrums = [t for i, t in enumerate(tantrums) if i not in to_remove]\n",
    "\n",
    "    # tantrums = [t for idx, t in enumerate(tantrums) if idx not in overlapping_tantrums]\n",
    "    tantrum_starts = [ts for (ts, _) in tantrums]\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Removed {sum(invalid_count.values())} invalid tantrums: {invalid_count}\"\n",
    "        )\n",
    "    return pd.Series(tantrum_starts)\n",
    "\n",
    "\n",
    "def has_tantrum_within_period_minutes(\n",
    "    tantrum_starts: np.ndarray, activity_time: pd.DatetimeIndex, period_minutes: int\n",
    "):\n",
    "    # Find if any tantrum starts within the specified period after activity_time\n",
    "    return np.any(\n",
    "        (tantrum_starts >= activity_time)\n",
    "        & (tantrum_starts < activity_time + pd.Timedelta(minutes=period_minutes))\n",
    "    )\n",
    "\n",
    "\n",
    "def most_recent_hrs(\n",
    "    hr_df: pd.DataFrame, time: datetime, lookback: pd.Timedelta\n",
    ") -> pd.Series:\n",
    "    \"\"\"Get the last N heart rate measurements before a certain time.\n",
    "\n",
    "    Assumes hr_df is sorted by ActivityTime.\n",
    "\n",
    "    Returns a Series of variable length\n",
    "    \"\"\"\n",
    "    end = time\n",
    "    start = time - lookback\n",
    "\n",
    "    # Runs in O(log N) time if df is sorted by ActivityTime\n",
    "    left_idx = hr_df[\"ActivityTime\"].searchsorted(start)\n",
    "    right_idx = hr_df[\"ActivityTime\"].searchsorted(end)\n",
    "    recent_hrs = hr_df.iloc[left_idx:right_idx][\"HeartRate\"]\n",
    "    return recent_hrs\n",
    "\n",
    "\n",
    "def pad_or_truncate_series(s: pd.Series, length: int):\n",
    "    \"\"\"Convert a Series to a fixed-length numpy array, padding with NaNs if necessary.\"\"\"\n",
    "    # Convert s to float type so padding with np.nan works correctly\n",
    "    s = s.astype(float)\n",
    "    arr = (\n",
    "        s.values[-length:]\n",
    "        if len(s) >= length\n",
    "        else np.pad(s.values, (length - len(s), 0), constant_values=np.nan)\n",
    "    )\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_dyads = dyads_df[dyads_df[\"Arm\"] == \"Active\"].index.tolist()\n",
    "sham_dyads = dyads_df[dyads_df[\"Arm\"] == \"Sham\"].index.tolist()\n",
    "counts = {\n",
    "    \"active\": 0,\n",
    "    \"sham\": 0,\n",
    "}\n",
    "for dyad in dyads_df.index:\n",
    "    tantrums = tantrum_onsets_from_ilumivu_dfs(\n",
    "        *get_ilumivu_dfs(f\"{dyad:03d}\"), verbose=True\n",
    "    )\n",
    "    if dyad in active_dyads:\n",
    "        counts[\"active\"] += len(tantrums)\n",
    "    else:\n",
    "        counts[\"sham\"] += len(tantrums)\n",
    "\n",
    "print()\n",
    "print(counts)\n",
    "avg_active = counts[\"active\"] / len(active_dyads)\n",
    "avg_sham = counts[\"sham\"] / len(sham_dyads)\n",
    "print(\"Active dyads: \", len(active_dyads))\n",
    "print(\"Sham dyads: \", len(sham_dyads))\n",
    "print(f\"Average tantrum count per active dyad: {avg_active:.2f}\")\n",
    "print(f\"Average tantrum count per sham dyad: {avg_sham:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62547dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "pbar = tqdm(dyads_df.index.tolist())\n",
    "for dyad in pbar:\n",
    "    pbar.set_description(f\"Processing dyad {dyad}\")\n",
    "    dyad_df = make_dyad_df(dyad)\n",
    "    dyad_df[\"dyad\"] = dyad\n",
    "\n",
    "    data_df = pd.concat([data_df, dyad_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f02386",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(DATA_DIR / \"all_dyads.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pistachio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
